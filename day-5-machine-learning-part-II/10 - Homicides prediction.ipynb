{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime prediction using statistical learning and urban metrics\n",
    "\n",
    "* Data description: metric distributions are non-gaussians;\n",
    "* Co-linearity: correlations between metrics;\n",
    "* Regression model;\n",
    "* Machine learning approach;\n",
    "- Underfitting and Overfitting;\n",
    "- Prediction vs. data;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T02:58:19.943699Z",
     "start_time": "2019-06-24T02:58:19.917685Z"
    }
   },
   "outputs": [],
   "source": [
    "#sets the notebook width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T02:58:20.982281Z",
     "start_time": "2019-06-24T02:58:20.962853Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T02:58:25.878330Z",
     "start_time": "2019-06-24T02:58:22.973009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "# Third Party Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as plticker\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.multitest as smm            \n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T02:58:25.962407Z",
     "start_time": "2019-06-24T02:58:25.882571Z"
    }
   },
   "outputs": [],
   "source": [
    "def stdfigsize(scale=1, nx=1, ny=1, ratio=1.3):\n",
    "    \"\"\"\n",
    "    Returns a tuple to be used as figure size.\n",
    "    -------\n",
    "    returns (7*ratio*scale*nx, 7.*scale*ny)\n",
    "    By default: ratio=1.3\n",
    "    If ratio<0 them ratio = golden ratio\n",
    "    \"\"\"\n",
    "    if ratio < 0:\n",
    "        ratio = 1.61803398875\n",
    "    return((7*ratio*scale*nx, 7.*scale*ny))\n",
    "\n",
    "def stdrcparams(usetex=False):\n",
    "    \"\"\"\n",
    "    Set several mpl.rcParams and sns.set_style for my taste.\n",
    "    ----\n",
    "    usetex = True\n",
    "    ----\n",
    "    \"\"\"\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_style({\"xtick.direction\": \"in\",\n",
    "                    \"ytick.direction\": \"in\"})\n",
    "    rcparams = {'text.usetex': usetex,\n",
    "              'font.family': 'sans-serif',\n",
    "              'font.sans-serif': ['Helvetica'],\n",
    "              'text.latex.unicode': True,\n",
    "              'text.latex.preamble': [r\"\\usepackage[T1]{fontenc}\",\n",
    "                                      r\"\\usepackage{lmodern}\",\n",
    "                                      r\"\\usepackage{amsmath}\",\n",
    "                                      r\"\\usepackage{mathptmx}\"\n",
    "                                      ],\n",
    "              'axes.labelsize': 30,\n",
    "              'axes.titlesize': 30,\n",
    "              'ytick.right': 'on',\n",
    "              'xtick.top': 'on',\n",
    "              'xtick.labelsize': '25',\n",
    "              'ytick.labelsize': '25',\n",
    "              'axes.linewidth': 1.8,\n",
    "              'xtick.major.width': 1.8,\n",
    "              'xtick.minor.width': 1.8,\n",
    "              'xtick.major.size': 14,\n",
    "              'xtick.minor.size': 7,\n",
    "              'xtick.major.pad': 10,\n",
    "              'xtick.minor.pad': 10,\n",
    "              'ytick.major.width': 1.8,\n",
    "              'ytick.minor.width': 1.8,\n",
    "              'ytick.major.size': 14,\n",
    "              'ytick.minor.size': 7,\n",
    "              'ytick.major.pad': 10,\n",
    "              'ytick.minor.pad': 10,\n",
    "              'axes.labelpad': 15,\n",
    "              'axes.titlepad': 15\n",
    "              }\n",
    "    mpl.rcParams.update(rcparams) \n",
    "\n",
    "stdrcparams(usetex=True)\n",
    "figsize=stdfigsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T02:58:26.042769Z",
     "start_time": "2019-06-24T02:58:25.966512Z"
    }
   },
   "outputs": [],
   "source": [
    "def winm(x, y, nw):\n",
    "    xw = []\n",
    "    yw = []\n",
    "    step = (max(x) - min(x)) / nw\n",
    "    lw = [min(x) + step * i for i in range(0, nw)]\n",
    "    for i in range(0, len(lw) - 1):\n",
    "        if len(y[x > lw[i]][x[x > lw[i]] < lw[i + 1]]) > 0:\n",
    "            xw.append(np.mean(x[x > lw[i]][x[x > lw[i]] < lw[i + 1]]))\n",
    "            yw.append(np.mean(y[x > lw[i]][x[x > lw[i]] < lw[i + 1]]))\n",
    "    return (np.array(xw), np.array(yw))\n",
    "\n",
    "def f(x,a,b):\n",
    "    return a*x+b\n",
    "\n",
    "def box_plot_style(ax,bp,ymin=0,ymax=1,ylabel='y',xticklabels=None,fontsize=20):\n",
    "    ## change outline color, fill color and linewidth of the boxes\n",
    "    for box in bp['boxes']:\n",
    "        # change outline color\n",
    "        box.set( color='black', linewidth=1)\n",
    "        # change fill color\n",
    "        box.set( facecolor='#bdbdbd',zorder=3)\n",
    "\n",
    "    ## change color and linewidth of the whiskers\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(linestyle='-',color='black', linewidth=1,zorder=4)\n",
    "\n",
    "    ## change color and linewidth of the caps\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color='black', linewidth=1,zorder=4)\n",
    "\n",
    "    ## change color and linewidth of the medians\n",
    "    for median in bp['medians']:\n",
    "        median.set(color='k', linewidth=1,zorder=4)\n",
    "\n",
    "    ## change the style of fliers and their fill\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker='o', markerfacecolor='k',\n",
    "                  markeredgecolor='k',markersize=4,zorder=3)\n",
    "\n",
    "    ## Remove top axes and right axes ticks\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    \n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlabel(' ',ha='center')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if xticklabels is not None:\n",
    "        ax.set_xticklabels(xticklabels,rotation=45, ha='right',fontsize=fontsize)\n",
    "\n",
    "def test2samples(data_to_plot):\n",
    "    data_to_plot=data_to_plot.T\n",
    "    m,n=data_to_plot.shape\n",
    "    indexes=[]\n",
    "    new_p=[]\n",
    "    for j in range(0,m):\n",
    "        for i in range(0,m):\n",
    "            s1=[x for x in data_to_plot[j] if str(x) != 'nan']\n",
    "            s2=[x for x in data_to_plot[i] if str(x) != 'nan']\n",
    "            tstat, pvalue=stats.ttest_ind(s1,s2, equal_var = False)\n",
    "            #ustat, pvalue=stats.mannwhitneyu(s1,s2)\n",
    "            if i <j:\n",
    "                new_p.append(pvalue)\n",
    "                indexes.append((i, j))\n",
    "\n",
    "    # Plot p-values with correction for multiple testing    \n",
    "    a, corrected_p, c, d = smm.multipletests(new_p, method='b')\n",
    "    p_array = np.ones((m, m))\n",
    "    for (i, j), pv in zip(indexes, corrected_p):\n",
    "        p_array[i, j] = p_array[j, i] =  round(pv, ndigits=3)\n",
    "    return p_array\n",
    "\n",
    "def model_scores(prediction,testY):\n",
    "    df=pd.DataFrame(columns=[\"Metric\",\"Score\"])\n",
    "    df.loc[0]=[\"R-square\", metrics.r2_score(testY,prediction)]\n",
    "    df.loc[1]=[\"Explained variance\", metrics.explained_variance_score(testY,prediction)]\n",
    "    df.loc[2]=[\"Mean absolute error\", metrics.mean_absolute_error(testY,prediction)]\n",
    "    df.loc[3]=[\"Mean squared error\", metrics.mean_squared_error(testY,prediction)]\n",
    "    df.loc[4]=[\"Median absolute error\", metrics.median_absolute_error(testY,prediction)]  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:10:26.782962Z",
     "start_time": "2019-06-24T03:10:26.744959Z"
    }
   },
   "outputs": [],
   "source": [
    "indicators=['Population',\n",
    "       'Homicides', 'Suicides', 'Traffic accidents',\n",
    "       'Elderly population', 'Female population ', 'Male population','GDP',\n",
    "       'Income', 'Unemployment', 'Illiteracy', 'Sanitation', 'Child Labor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:10:27.576544Z",
     "start_time": "2019-06-24T03:10:27.483427Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets=dict()\n",
    "for year in [2000,2010]:\n",
    "    datasets[year]=pd.read_csv(f'../data/data-{year}.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:10:28.020983Z",
     "start_time": "2019-06-24T03:10:27.971797Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets[2000].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T23:21:42.796078Z",
     "start_time": "2017-07-21T23:21:42.742142Z"
    }
   },
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:10:33.336735Z",
     "start_time": "2019-06-24T03:10:29.340619Z"
    }
   },
   "outputs": [],
   "source": [
    "for year in [2000,2010]:\n",
    "    correlation=np.zeros((len(indicators),len(indicators)))\n",
    "    for i in range(0,len(indicators)):\n",
    "        for j in range(0,len(indicators)):\n",
    "            x=np.nan_to_num(datasets[year][indicators[i]])\n",
    "            y=np.nan_to_num(datasets[year][indicators[j]])\n",
    "            r,pvalue=stats.pearsonr(x,y)\n",
    "            correlation[i][j]=r\n",
    "    df_corr=pd.DataFrame(correlation,columns=indicators,index=indicators)     \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=stdfigsize(scale=1.2))\n",
    "    res=sns.heatmap(df_corr,vmin=0 ,vmax=1.,linewidth=1,cmap=\"Spectral\",square=True)\n",
    "    #ax.set_title(\"Year={}\".format(year))\n",
    "    cbar = res.collections[0].colorbar\n",
    "    cbar.set_ticks([0., 0.25,0.5, 0.75, 1])\n",
    "    cbar.set_ticklabels(['0.00', '0.25',\"0.50\", '0.75', '1.00'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T23:50:12.448024Z",
     "start_time": "2017-07-21T23:50:11.857720Z"
    }
   },
   "source": [
    "# Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:10:36.101301Z",
     "start_time": "2019-06-24T03:10:36.052648Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:03.054731Z",
     "start_time": "2019-06-24T03:11:02.829425Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dataset=datasets[2000][np.concatenate([indicators,[\"CityUF\"]])]\n",
    "df_dataset[\"Y\"]=np.array(datasets[2010][\"Homicides\"])\n",
    "df_dataset=df_dataset[df_dataset.Population>0]\n",
    "df_dataset=df_dataset.dropna()\n",
    "\n",
    "df_dataset=datasets[2000][indicators]\n",
    "df_dataset[\"Y\"]=np.array(datasets[2010][\"Homicides\"])\n",
    "df_dataset=df_dataset[df_dataset.Population>0]\n",
    "\n",
    "df_dataset=df_dataset.dropna()\n",
    "X=np.array(df_dataset[indicators])\n",
    "Y=np.array(df_dataset[\"Y\"])\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:04.213463Z",
     "start_time": "2019-06-24T03:11:04.034131Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:05.425460Z",
     "start_time": "2019-06-24T03:11:05.385722Z"
    }
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:06.268999Z",
     "start_time": "2019-06-24T03:11:05.965578Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "accuracy=[]\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "for i in range(0,100):\n",
    "    prediction.append([])\n",
    "    lm.fit(trainX,trainY)\n",
    "    prediction_lm=lm.predict(testX)\n",
    "    prediction[i]=prediction_lm.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:06.793553Z",
     "start_time": "2019-06-24T03:11:06.753449Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_lm= prediction[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:08.061761Z",
     "start_time": "2019-06-24T03:11:07.384270Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_xlabel(\"Data\")\n",
    "ax.set_ylabel(\"Prediction\")\n",
    "ax.plot(testY,prediction_lm,\"o\",markersize=12,color=\"red\",alpha=0.6)\n",
    "ax.plot(np.arange(1,max(testY),0.1),np.arange(1,max(testY),0.1),\"k--\",linewidth=3)\n",
    "#ax.legend(fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "#plt.savefig(\"../figures/data_vs_prediction.pdf\",bbox_inches='tight')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:09.307162Z",
     "start_time": "2019-06-24T03:11:09.254007Z"
    }
   },
   "outputs": [],
   "source": [
    "x=(np.array(prediction_lm)-np.array(testY))\n",
    "stats.kstest(x,'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:15.438079Z",
     "start_time": "2019-06-24T03:11:15.193337Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "x=(np.array(prediction_lm)-np.array(testY))\n",
    "res = stats.probplot(x, dist=stats.norm, plot=ax)\n",
    "ax.set_title('')\n",
    "ax.set_ylabel(\"Data quantiles\")\n",
    "ax.set_xlabel(\"Normal quantiles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:20.859487Z",
     "start_time": "2019-06-24T03:11:17.710320Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "accuracy=[]\n",
    "for i in range(0,1000):\n",
    "    prediction.append([])\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    lm.fit(trainX,trainY)\n",
    "    prediction_lm=lm.predict(testX)\n",
    "    accuracy.append(metrics.r2_score(testY,prediction_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:21.437534Z",
     "start_time": "2019-06-24T03:11:20.862199Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_ylabel(\"PDF\")\n",
    "ax.set_xlabel(\"Adjusted$-R^2$\")\n",
    "sns.distplot(accuracy,kde=True)\n",
    "#ax.set_yscale(\"log\")\n",
    "print(np.mean(accuracy),np.std(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:26.045430Z",
     "start_time": "2019-06-24T03:11:25.930412Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_df_lm=pd.DataFrame()\n",
    "importance_df_lm[\"Feature\"]=indicators\n",
    "for i in range(0,10):\n",
    "    df=df_dataset.sample(frac=1,replace=True)\n",
    "    X=np.array(df[indicators])\n",
    "    Y=np.array(df[\"Y\"])\n",
    "    lm.fit(X,Y)\n",
    "    importance_df_lm[i]=np.abs(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:27.094772Z",
     "start_time": "2019-06-24T03:11:27.044682Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_df_lm=importance_df_lm.set_index(\"Feature\").T\n",
    "features=list(importance_df_lm.columns)\n",
    "medians=[]\n",
    "for feature in features:\n",
    "    m=np.median(importance_df_lm[feature])\n",
    "    medians.append(m)\n",
    "\n",
    "importance_df_lm=importance_df_lm.T\n",
    "importance_df_lm[\"Medians\"]=medians\n",
    "\n",
    "importance_df_lm.sort_values(by=\"Medians\",inplace=True,ascending=False)\n",
    "del importance_df_lm['Medians']\n",
    "\n",
    "importance_df_lm=importance_df_lm.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:28.542022Z",
     "start_time": "2019-06-24T03:11:27.956726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a figure instance\n",
    "fig = plt.figure(1, figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid()\n",
    "bp = ax.boxplot(np.array(importance_df_lm), patch_artist=True,showfliers=True)\n",
    "## change outline color, fill color and linewidth of the boxes\n",
    "for box in bp['boxes']:\n",
    "    # change outline color\n",
    "    box.set( color='black', linewidth=1)\n",
    "    # change fill color\n",
    "    box.set( facecolor='#bdbdbd',zorder=3)\n",
    "\n",
    "## change color and linewidth of the whiskers\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(linestyle='-',color='black', linewidth=1,zorder=4)\n",
    "\n",
    "## change color and linewidth of the caps\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='black', linewidth=1,zorder=4)\n",
    "\n",
    "## change color and linewidth of the medians\n",
    "for median in bp['medians']:\n",
    "    median.set(color='k', linewidth=1,zorder=4)\n",
    "\n",
    "## change the style of fliers and their fill\n",
    "for flier in bp['fliers']:\n",
    "    flier.set(marker='o', markerfacecolor='k',\n",
    "              markeredgecolor='k',markersize=4,zorder=3)\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('Feature importance')\n",
    "#ax.set_yscale('log')\n",
    "ax.set_ylim(-1,2)\n",
    "ax.set_xticklabels(labels=list(importance_df_lm.columns),rotation=90)\n",
    "#plt.savefig(\"../figures/features_importance.pdf\",bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:35.575872Z",
     "start_time": "2019-06-24T03:11:35.046653Z"
    }
   },
   "outputs": [],
   "source": [
    "p=test2samples(np.array(importance_df_lm))\n",
    "p=pd.DataFrame(p,index=list(importance_df_lm.columns),columns=list(importance_df_lm.columns))\n",
    "fig, ax = plt.subplots(figsize=stdfigsize(scale=1.2))\n",
    "res=sns.heatmap(p,vmin=0,vmax=1.,linewidths=1,annot=False,cmap=\"Reds\",square=True)\n",
    "cbar = res.collections[0].colorbar\n",
    "cbar.set_ticks([0,0.25, 0.5,0.75, 1])\n",
    "cbar.set_ticklabels([\"0.00\",\"0.25\", \"0.50\",\"0.75\", \"1.00\"])\n",
    "ax.tick_params(labelsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T18:04:53.173586Z",
     "start_time": "2017-07-22T18:04:53.142780Z"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:48.993818Z",
     "start_time": "2019-06-24T03:11:48.889436Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:49.763068Z",
     "start_time": "2019-06-24T03:11:49.412809Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dataset=datasets[2000][np.concatenate([indicators,[\"CityUF\"]])]\n",
    "df_dataset[\"Y\"]=np.array(datasets[2010][\"Homicides\"])\n",
    "df_dataset=df_dataset[df_dataset.Population>0]\n",
    "df_dataset=df_dataset.dropna()\n",
    "df_dataset.to_csv(\"../results/data.xls\")\n",
    "\n",
    "df_dataset=datasets[2000][indicators]\n",
    "df_dataset[\"Y\"]=np.array(datasets[2010][\"Homicides\"])\n",
    "df_dataset=df_dataset[df_dataset.Population>0]\n",
    "\n",
    "df_dataset=df_dataset.dropna()\n",
    "X=np.array(df_dataset[indicators])\n",
    "Y=np.array(df_dataset[\"Y\"])\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:11:52.103640Z",
     "start_time": "2019-06-24T03:11:52.063796Z"
    }
   },
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(n_estimators=200,\n",
    "                    criterion='mse', \n",
    "                    max_depth=50, \n",
    "                    min_samples_split=2, \n",
    "                    min_samples_leaf=1, \n",
    "                    min_weight_fraction_leaf=0.0, \n",
    "                    max_features='auto', \n",
    "                    max_leaf_nodes=None, \n",
    "                    min_impurity_split=1e-07, \n",
    "                    bootstrap=True, \n",
    "                    oob_score=False, \n",
    "                    n_jobs=-1, \n",
    "                    random_state=None, \n",
    "                    verbose=0,\n",
    "                    warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-23T14:31:19.302881Z",
     "start_time": "2017-07-23T14:31:19.268251Z"
    }
   },
   "source": [
    "In statistics and machine learning, the bias–variance tradeoff (or dilemma) is the problem of simultaneously minimizing two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:\n",
    "\n",
    "**Underfitting**: The bias is error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
    "\n",
    "**Overfitting**: The variance is error from sensitivity to small fluctuations in the training set. High variance can cause overfitting: modeling the random noise in the training data, rather than the intended outputs.\n",
    "\n",
    "\n",
    "Finding an $\\hat {f}$ that generalizes to points outside of the training set can be done with any of the countless algorithms used for supervised learning. It turns out that whichever function $\\hat {f}$ we select, we can decompose its expected error on an unseen sample $x$ as follows*\n",
    "\n",
    "\\begin{aligned}{\\mathrm  {E}}{\\Big [}{\\big (}y-{\\hat  {f}}(x){\\big )}^{2}{\\Big ]}&={\\mathrm  {Bias}}{\\big [}{\\hat  {f}}(x){\\big ]}^{2}+{\\mathrm  {Var}}{\\big [}{\\hat  {f}}(x){\\big ]}+\\sigma ^{2}\\\\\\end{aligned}\n",
    "Where:\n",
    "\n",
    "\\begin{aligned}\\mathrm {Bias} {\\big [}{\\hat {f}}(x){\\big ]}=\\mathrm {E} {\\big [}{\\hat {f}}(x)-f(x){\\big ]}\\end{aligned}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{aligned}\\mathrm {Var} {\\big [}{\\hat {f}}(x){\\big ]}=\\mathrm {E} [{\\hat {f}}(x)^{2}]-\\mathrm {E} [{\\hat {f}}(x)]^{2}\\end{aligned}\n",
    "\n",
    "\n",
    "* Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:12:30.134622Z",
     "start_time": "2019-06-24T03:12:24.745658Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = trainX,trainY\n",
    "param_range =np.logspace(0.1,1,3).astype(int)\n",
    "train_scores, test_scores = validation_curve(RandomForestRegressor().set_params(**{'bootstrap': True,\n",
    "                                                           'max_depth': 50,\n",
    "                                                           'max_features': 'auto',\n",
    "                                                           'min_samples_split': 2}), \n",
    "                                             X, y, \n",
    "                                             param_name=\"n_estimators\", \n",
    "                                             param_range=param_range,\n",
    "                                             cv=10, \n",
    "                                             scoring=None, \n",
    "                                             n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:12:30.901468Z",
     "start_time": "2019-06-24T03:12:30.853212Z"
    }
   },
   "outputs": [],
   "source": [
    "np.logspace(0.1,1,3).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T16:23:04.984761Z",
     "start_time": "2017-07-24T16:23:04.944709Z"
    }
   },
   "source": [
    "In this plot you can see the training scores and validation scores of a Random Forest Regressor for different values of the parameter n_estimators (Number of trees). For very low values of n_estimators, you can see that both the training score and the validation score are slightly lower. This is called underfitting. Medium values of n_estimators will result in high values for both scores, i.e. the regressor is performing fairly well. If n_estimators is too high, the regressors will overfit, which means that the training score is good but the validation score is poor. We do not see this here because up to 10000 trees the model is still performing well.\n",
    "\n",
    "See more at: \n",
    "* http://scikit-learn.org/stable/modules/learning_curve.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:12:36.031227Z",
     "start_time": "2019-06-24T03:12:35.620961Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "ax.set_xlabel(\"Number of trees\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim(0.2,1.05)\n",
    "lw = 2\n",
    "#ax.grid()\n",
    "ax.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"#e41a1c\", lw=lw)\n",
    "ax.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"#e41a1c\", lw=lw)\n",
    "ax.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"#377eb8\", lw=lw)\n",
    "ax.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"#377eb8\", lw=lw)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(loc=\"lower left\",fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-24T16:12:08.828646Z",
     "start_time": "2017-07-24T16:12:02.998006Z"
    }
   },
   "source": [
    "#### Maximal depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:18.986492Z",
     "start_time": "2019-06-24T03:12:43.770034Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = trainX,trainY\n",
    "param_range_max_depth =np.logspace(0.1,2,3).astype(int)\n",
    "train_scores, test_scores = validation_curve(RandomForestRegressor(n_estimators=100), \n",
    "                                             X, y, \n",
    "                                             param_name=\"max_depth\", \n",
    "                                             param_range=param_range_max_depth,\n",
    "                                             cv=10, \n",
    "                                             scoring=None, \n",
    "                                             n_jobs=-1)\n",
    "\n",
    "train_scores_mean_max_depth = np.mean(train_scores, axis=1)\n",
    "train_scores_std_max_depth = np.std(train_scores, axis=1)\n",
    "test_scores_mean_max_depth = np.mean(test_scores, axis=1)\n",
    "test_scores_std_max_depth = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:18.990337Z",
     "start_time": "2019-06-24T03:12:45.702Z"
    }
   },
   "outputs": [],
   "source": [
    "param_range_max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:18.992519Z",
     "start_time": "2019-06-24T03:12:49.647Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "ax.set_xlabel(\"Maximum depth\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim(0.5,1.05)\n",
    "lw = 2\n",
    "ax.plot(param_range_max_depth, train_scores_mean_max_depth, label=\"Training score\",\n",
    "             color=\"#e41a1c\", lw=lw)\n",
    "ax.fill_between(param_range_max_depth, train_scores_mean_max_depth - train_scores_std_max_depth,\n",
    "                 train_scores_mean_max_depth + train_scores_std_max_depth, alpha=0.2,\n",
    "                 color=\"#e41a1c\", lw=lw)\n",
    "ax.plot(param_range_max_depth, test_scores_mean_max_depth, label=\"Cross-validation score\",\n",
    "             color=\"#377eb8\", lw=lw)\n",
    "ax.fill_between(param_range_max_depth, test_scores_mean_max_depth - test_scores_std_max_depth,\n",
    "                 test_scores_mean_max_depth + test_scores_std_max_depth, alpha=0.2,\n",
    "                 color=\"#377eb8\", lw=lw)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(loc=\"lower right\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:18.994936Z",
     "start_time": "2019-06-24T03:13:03.176Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = trainX,trainY\n",
    "estimator = RandomForestRegressor(n_jobs=-1).set_params(**{'bootstrap': True,\n",
    "                                                           'max_depth': 50,\n",
    "                                                           'max_features': 'auto',\n",
    "                                                           'min_samples_split': 2,\n",
    "                                                           'n_estimators': 100})\n",
    "train_sizes_lc=np.linspace(.1, 1.0, 3)\n",
    "\n",
    "train_sizes_lc, train_scores, test_scores = learning_curve(estimator, \n",
    "                                                        X, \n",
    "                                                        y, \n",
    "                                                        cv=10, \n",
    "                                                        n_jobs=-1, \n",
    "                                                        train_sizes=train_sizes_lc)\n",
    "train_scores_mean_lc = np.mean(train_scores, axis=1)\n",
    "train_scores_std_lc = np.std(train_scores, axis=1)\n",
    "test_scores_mean_lc = np.mean(test_scores, axis=1)\n",
    "test_scores_std_lc = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the curve for the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. However, we can see a maximum around 2500, showning that, actually, given more data is not making it better. \n",
    "\n",
    "See more at:\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:18.998364Z",
     "start_time": "2019-06-24T03:13:10.278Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_xlabel(\"Fraction of training data\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim(0.5,1.05)\n",
    "#ax.grid()\n",
    "ax.fill_between(np.linspace(.1, 1.0, 8), train_scores_mean_lc - train_scores_std_lc,\n",
    "                 train_scores_mean_lc + train_scores_std_lc, alpha=0.2,\n",
    "                 color=\"#e41a1c\")\n",
    "ax.fill_between(np.linspace(.1, 1.0, 8), test_scores_mean_lc - test_scores_std_lc,\n",
    "                 test_scores_mean_lc + test_scores_std_lc, alpha=0.2, color=\"#377eb8\")\n",
    "ax.plot(np.linspace(.1, 1.0, 8), train_scores_mean_lc, '-', color=\"#e41a1c\",\n",
    "         label=\"Training score\")\n",
    "ax.plot(np.linspace(.1, 1.0, 8), test_scores_mean_lc, '-', color=\"#377eb8\",\n",
    "         label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"lower right\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main parameters to adjust when using these methods is n_estimators and max_features. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. Empirical good default values are max_features=n_features for regression problems, and max_features=sqrt(n_features) for classification tasks (where n_features is the number of features in the data). Good results are often achieved when setting max_depth=None in combination with min_samples_split=1 (i.e., when fully developing the trees). Bear in mind though that these values are usually not optimal, and might result in models that consume a lot of RAM. The best parameter values should always be cross-validated. In addition, note that in random forests, bootstrap samples are used by default (bootstrap=True) while the default strategy for extra-trees is to use the whole dataset (bootstrap=False). When using bootstrap sampling the generalization accuracy can be estimated on the left out or out-of-bag samples. This can be enabled by setting oob_score=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:19.000537Z",
     "start_time": "2019-06-24T03:13:14.142Z"
    }
   },
   "outputs": [],
   "source": [
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = {  \"n_estimators\": [100,200,500],\n",
    "                    \"max_depth\":[10,50,100],\n",
    "                    \"max_features\": [\"auto\"],\n",
    "                    \"min_samples_split\" : [2,4,8],\n",
    "                    \"bootstrap\": [True,False]}\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=10)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:19.002616Z",
     "start_time": "2019-06-24T03:13:15.837Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score_rf,best_params_rf=Grid_Search_CV_RFR(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:33.570417Z",
     "start_time": "2019-06-24T03:13:33.527797Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score_rf,best_params_rf=(0.89291467777356359,\n",
    " {'bootstrap': True,\n",
    "  'max_depth': 100,\n",
    "  'max_features': 'auto',\n",
    "  'min_samples_split': 4,\n",
    "  'n_estimators': 200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the data and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:38.679500Z",
     "start_time": "2019-06-24T03:13:38.639814Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1).set_params(**{'bootstrap': True,\n",
    "  'max_depth': 100,\n",
    "  'max_features': 'auto',\n",
    "  'min_samples_split': 4,\n",
    "  'n_estimators': 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T03:13:39.459233Z",
     "start_time": "2019-06-24T03:13:39.418972Z"
    }
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:13:40.712Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "accuracy=[]\n",
    "for i in range(0,100):\n",
    "    prediction.append([])\n",
    "    rf.fit(trainX,trainY)\n",
    "    prediction_rf=rf.predict(testX)\n",
    "    prediction[i]=prediction_rf.astype(int)\n",
    "    accuracy.append(rf.score(testX,testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:13:41.841Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_rf=np.median(prediction,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:13:50.159Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_xlabel(\"Data\")\n",
    "ax.set_ylabel(\"Prediction\")\n",
    "ax.plot(testY,prediction_rf,\"o\",markersize=12,color=\"red\",alpha=0.6)\n",
    "ax.plot(np.arange(1,max(testY),0.1),np.arange(1,max(testY),0.1),\"k--\",linewidth=3)\n",
    "#ax.legend(fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:13:55.186Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.set_xlabel(\"Data points\")\n",
    "ax.plot((np.array(prediction_rf)-np.array(testY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:13:58.887Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_ylabel(\"PDF\")\n",
    "ax.set_xlabel(\"Residuals\")\n",
    "sns.distplot((np.array(prediction_rf)-np.array(testY)),kde=False)\n",
    "print(np.mean(np.array(prediction_rf)-np.array(testY)),np.std(np.array(prediction_rf)-np.array(testY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:00.339Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "accuracy=[]\n",
    "for i in range(0,100):\n",
    "    prediction.append([])\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    rf.fit(trainX,trainY)\n",
    "    prediction_rf=rf.predict(testX)\n",
    "    accuracy.append(metrics.r2_score(testY,prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:02.782Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_ylabel(\"PDF\")\n",
    "ax.set_xlabel(\"Adjusted$-R^2$\")\n",
    "sns.distplot(accuracy,kde=True)\n",
    "#ax.set_yscale(\"log\")\n",
    "print(np.mean(accuracy),np.std(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:03.895Z"
    }
   },
   "outputs": [],
   "source": [
    "max(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:04.975Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df=model_scores(prediction_rf,testY)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:06.796Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_df=pd.DataFrame()\n",
    "importance_df[\"Feature\"]=indicators\n",
    "for i in range(0,100):\n",
    "    X=np.array(df_dataset[indicators])\n",
    "    Y=np.array(df_dataset[\"Y\"])\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    rf.fit(trainX,trainY)\n",
    "    importance_df[i]=rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:09.229Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:09.975Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_df=importance_df.set_index(\"Feature\").T\n",
    "features=list(importance_df.columns)\n",
    "medians=[]\n",
    "for feature in features:\n",
    "    m=np.median(importance_df[feature])\n",
    "    medians.append(m)\n",
    "\n",
    "importance_df=importance_df.T\n",
    "importance_df[\"Medians\"]=medians\n",
    "\n",
    "importance_df.sort_values(by=\"Medians\",inplace=True,ascending=False)\n",
    "del importance_df['Medians']\n",
    "\n",
    "importance_df=importance_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:13.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a figure instance\n",
    "fig = plt.figure(1, figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "bp = ax.boxplot(np.array(importance_df), patch_artist=True,showfliers=True)\n",
    "\n",
    "for box in bp['boxes']:\n",
    "    # change outline color\n",
    "    box.set( color='black', linewidth=1)\n",
    "    # change fill color\n",
    "    box.set( facecolor='#bdbdbd',zorder=3)\n",
    "\n",
    "## change color and linewidth of the whiskers\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(linestyle='-',color='black', linewidth=1,zorder=4)\n",
    "\n",
    "## change color and linewidth of the caps\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='black', linewidth=1,zorder=4)\n",
    "\n",
    "## change color and linewidth of the medians\n",
    "for median in bp['medians']:\n",
    "    median.set(color='k', linewidth=1,zorder=4)\n",
    "\n",
    "## change the style of fliers and their fill\n",
    "for flier in bp['fliers']:\n",
    "    flier.set(marker='o', markerfacecolor='k',\n",
    "              markeredgecolor='k',markersize=4,zorder=3)\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Feature importance')\n",
    "ax.set_xticklabels(list(importance_df.columns),rotation=90,ha='center')\n",
    "#box_plot_style(ax,bp,ymin=0,ymax=0.46,ylabel='Feature imp,ortance',xticklabels=list(importance_df.columns),fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:17.777Z"
    }
   },
   "outputs": [],
   "source": [
    "p=test2samples(np.array(importance_df))\n",
    "p=pd.DataFrame(p,index=list(importance_df.columns),columns=list(importance_df.columns))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=stdfigsize(scale=1.2))\n",
    "res=sns.heatmap(p,vmin=0,vmax=1.,linewidths=1,annot=False,cmap=\"Reds\",square=True)\n",
    "#sns.clustermap(p,vmin=0,vmax=1.,annot=False,cmap=\"Reds\")\n",
    "\n",
    "cbar = res.collections[0].colorbar\n",
    "cbar.set_ticks([0,0.25, 0.5,0.75, 1])\n",
    "cbar.set_ticklabels([\"0.00\",\"0.25\", \"0.50\",\"0.75\", \"1.00\"])\n",
    "#ax.tick_params(labelsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-24T03:14:19.826Z"
    }
   },
   "outputs": [],
   "source": [
    "indicators=['Child Labor',\n",
    "             'Elderly population',\n",
    "             'Female population ',\n",
    "             'GDP',\n",
    "             'Homicides',\n",
    "             'Illiteracy',\n",
    "             'Income',\n",
    "             'Male population',\n",
    "             'Population',\n",
    "             'Sanitation',\n",
    "             'Suicides',\n",
    "             'Traffic accidents',\n",
    "             'Unemployment']\n",
    "\n",
    "df_dataset=datasets[2000][np.concatenate([indicators,[\"CityUF\"]])]\n",
    "df_dataset[\"Y\"]=np.array(datasets[2010][\"Homicides\"])\n",
    "df_dataset=df_dataset[df_dataset.Population>0]\n",
    "df_dataset=df_dataset.dropna()\n",
    "\n",
    "df_dataset=datasets[2000][indicators]\n",
    "df_dataset[\"Y\"]=np.array(datasets[2010][\"Homicides\"])\n",
    "df_dataset=df_dataset[df_dataset.Population>0]\n",
    "\n",
    "df_dataset=df_dataset.dropna()\n",
    "X=np.array(df_dataset[indicators])\n",
    "Y=np.array(df_dataset[\"Y\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
